{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efa8bcee-a9c7-4ea2-90bf-2401ca153751",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de9ce28-caeb-46dc-be6e-ad69f799e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Environment to avoid using too many resources.\n",
    "# Just in case slurm isn't available\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"]         = \"12\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"]    = \"12\"\n",
    "os.environ[\"MKL_NUM_THREADS\"]         = \"12\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"]  = \"12\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"]     = \"12\"\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# IMPORT TORCH\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# IMPORT SELFEEG \n",
    "import selfeeg\n",
    "import selfeeg.models as zoo\n",
    "import selfeeg.dataloading as dl\n",
    "import selfeeg.augmentation as aug\n",
    "from selfeeg.ssl import fine_tune as train_model\n",
    "\n",
    "# IMPORT REPOSITORY FUNCTIONS\n",
    "from AllFnc import split\n",
    "from AllFnc.models import TransformEEG, TransformeegEncoder\n",
    "from AllFnc.pretraining import pretrain_model, VICReg, vicreg_loss\n",
    "from AllFnc.training import loadEEG, load_eeg_pretrain, set_augmenter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message= \"numpy.core.numeric is deprecated\",\n",
    "    category=DeprecationWarning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388d181d-b649-42c4-a159-dac934835008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reset_seed(seed):\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed(seed)\n",
    "            torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e237dd-14a2-46cb-8cef-306965b63f90",
   "metadata": {},
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d02ff2a-f3fd-409e-af89-72a5f365be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath       = '/data/datasets/eegpickle/'\n",
    "pipelineToEval = 'ica'\n",
    "modelToEval    = 'transformeeg'\n",
    "augment_list   = ['masking', 'masking'] # masking will be done only once\n",
    "chans_reduced  = False\n",
    "downsample     = True\n",
    "z_score        = True\n",
    "rem_interp     = True\n",
    "rem_noise      = False\n",
    "batchsize      = 1024\n",
    "overlap        = 0.25\n",
    "window         = 16\n",
    "workers        = 0\n",
    "verbose        = True\n",
    "lr             = 2.5e-4\n",
    "weight_decay   = None\n",
    "device         = \"cuda:0\"\n",
    "seed           = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa748be2-f437-46b7-b3b4-2858fd612c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set torch parameters\n",
    "torch.use_deterministic_algorithms(True, warn_only=False)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Define the device to use\n",
    "if device is None:\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "else:\n",
    "    device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2b8fff-260c-4906-abed-8ed41c25f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataPath[-1] != os.sep:\n",
    "    dataPath += os.sep\n",
    "if pipelineToEval[-1] != os.sep:\n",
    "    eegpath = dataPath + pipelineToEval + os.sep\n",
    "else:\n",
    "    eegpath = dataPath + pipelineToEval\n",
    "\n",
    "if rem_interp:\n",
    "    if chans_reduced:\n",
    "        Chan = 19\n",
    "    else:\n",
    "        Chan = 32\n",
    "else:\n",
    "    Chan = 61\n",
    "\n",
    "freq = 125 if downsample else 250\n",
    "Samples = int(freq*window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e386f6da-96df-48f7-86c4-185afd82f039",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d18fff8-b11c-47ed-9bb8-1fcc95ce55c4",
   "metadata": {},
   "source": [
    "## Load and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c13e13-3086-4d74-af91-3e4800f651af",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_eeg_args = {\n",
    "    'downsample':         downsample, \n",
    "    'use_only_original':  rem_interp,\n",
    "    'reduce_to_nineteen': chans_reduced,\n",
    "    'apply_zscore':       z_score,\n",
    "    'detect_noise':       rem_noise,\n",
    "    'winlen':             window,\n",
    "    'overlap':            overlap\n",
    "}\n",
    "\n",
    "# See BIDSAlign info table at\n",
    "# https://github.com/MedMaxLab/BIDSAlign/blob/main/DATASET_INFO.tsv\n",
    "glob_input = [\n",
    "    '2_*.pickle',  # ds004148 - Eyes Open Closed    - 60 Subj\n",
    "    '5_*.pickle',  # ds003490 - PD vs CTL           - 50 Subj\n",
    "    '8_*.pickle',  # ds002778 - PD vs CTL           - 31 Subj\n",
    "    '6_*.pickle',  # tdbrain  - Multiple conditions - 1274 Subj\n",
    "    '10_*.pickle', # ds004504 - AD vs FTD vs CTL    - 88 Subj\n",
    "    '19_*.pickle', # ds004584 - CTL vs PD           - 149 Subj\n",
    "    '21_*.pickle', # CAUEEG   - Multiple neurodeg   - 1379 subjects\n",
    "    '26_*.pickle', # BrainLat - Multiple neurodeg   - 125 subjects\n",
    "]\n",
    "try: \n",
    "    EEGlen = pd.read_csv('pretrain_dataset_length.csv', index_col=0)\n",
    "except Exception:\n",
    "    EEGlen = dl.get_eeg_partition_number(\n",
    "        eegpath, freq, window, overlap, \n",
    "        file_format             = glob_input,\n",
    "        load_function           = load_eeg_pretrain,\n",
    "        optional_load_fun_args  = load_eeg_args,\n",
    "        includePartial          = True,\n",
    "        verbose                 = verbose,\n",
    "        save                    = True,\n",
    "        save_path               = 'pretrain_dataset_length.csv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1750c42-cfaa-42ab-bbb8-f08384c2851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id_ex  = lambda x: int(x.split(os.sep)[-1].split('_')[0])\n",
    "subject_id_ex  = lambda x: int(x.split(os.sep)[-1].split('_')[1])\n",
    "\n",
    "EEGsplit= dl.get_eeg_split_table(\n",
    "    partition_table      = EEGlen,\n",
    "    exclude_data_id      = None,\n",
    "    val_data_id          = {19: None}, #{5:None, 8: None},\n",
    "    val_ratio            = 0.0,\n",
    "    test_ratio           = 0.0, \n",
    "    split_tolerance      = 0.0001,\n",
    "    dataset_id_extractor = dataset_id_ex,\n",
    "    subject_id_extractor = subject_id_ex,\n",
    "    perseverance         = 10000,\n",
    "    seed                 = seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444f25a2-a383-41e8-85b4-dc9ecf8457ed",
   "metadata": {},
   "source": [
    "## Build dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3646e51-3d95-4079-93b4-2d4dc6b17be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = dl.EEGDataset(\n",
    "    EEGlen, EEGsplit, [freq, window, overlap], 'train', \n",
    "    supervised             = False, \n",
    "    label_on_load          = False,\n",
    "    load_function          = load_eeg_pretrain,\n",
    "    optional_load_fun_args = load_eeg_args\n",
    ")\n",
    "if verbose:\n",
    "    print(\"Loading training set\")\n",
    "trainset.preload_dataset()\n",
    "\n",
    "valset = dl.EEGDataset(\n",
    "    EEGlen, EEGsplit, [freq, window, overlap], 'validation',\n",
    "    supervised             = False, \n",
    "    label_on_load          = False,\n",
    "    load_function          = load_eeg_pretrain,\n",
    "    optional_load_fun_args = load_eeg_args,\n",
    ")\n",
    "if verbose:\n",
    "    print(\"Loading validation set\")\n",
    "valset.preload_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adfee6d-e1cc-45ea-836c-503b1503bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsampler = dl.EEGSampler(data_source=trainset, BatchSize=batchsize, Workers=1)\n",
    "trainloader = DataLoader(dataset=trainset, batch_size=batchsize, sampler=trainsampler)\n",
    "valloader = DataLoader(dataset=valset, batch_size=batchsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343798a1-e878-41b5-8059-f4acbc7fc127",
   "metadata": {},
   "source": [
    "# Model pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560883f3-f54b-4240-b25e-787121f38428",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12341089-232e-4e0b-a6cc-add073b9a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFnc = vicreg_loss\n",
    "lossVal = vicreg_loss\n",
    "\n",
    "preaugmenter = set_augmenter(['phase_swap', 'phase_swap'], fs=freq, winlen=window)\n",
    "\n",
    "# Set data augmentation\n",
    "augment_list   = ['masking', 'masking']\n",
    "if augment_list is None:\n",
    "    augmenter = None\n",
    "else:\n",
    "    augmenter = set_augmenter(augment_list, fs=freq, winlen=window, p=None)\n",
    "\n",
    "\n",
    "_reset_seed(seed)\n",
    "mdl_encoder = TransformeegEncoder(Chan, seed=seed)\n",
    "if chans_reduced:\n",
    "    mdl_siamese = VICReg(mdl_encoder, [76, 128])\n",
    "else:\n",
    "    mdl_siamese = VICReg(mdl_encoder, [128, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7d11eb-4082-41be-bb58-1521654e6d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_initialized = copy.deepcopy(mdl_siamese).to(device='cpu')\n",
    "mdl_siamese.to(device = device)\n",
    "mdl_siamese.train()\n",
    "if verbose:\n",
    "    print(' ')\n",
    "    ParamTab = selfeeg.utils.count_parameters(mdl_siamese, False, True, True)\n",
    "    print(' ')\n",
    "    \n",
    "if verbose:\n",
    "    print(' ')\n",
    "    print('used learning rate', lr)\n",
    "\n",
    "gamma = 0.995\n",
    "optimizer = torch.optim.Adam(\n",
    "    mdl_siamese.parameters(),\n",
    "    betas = (0.75, 0.999),\n",
    "    lr = lr,\n",
    "    weight_decay = 0\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = gamma)\n",
    "mask_func = lambda x: 0.5  - 0.3**(x/25 + 1)\n",
    "\n",
    "# Define selfEEG's EarlyStopper with large patience to act as a model checkpoint\n",
    "earlystop = selfeeg.ssl.EarlyStopping(\n",
    "    patience  = 500, \n",
    "    min_delta = 1e-04, \n",
    "    record_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c555e5a5-1f76-47d5-9f4f-e82cd3d3d78d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lossVal = selfeeg.losses.vicreg_loss\n",
    "validation_loss_args = []\n",
    "#_reset_seed(seed)\n",
    "\n",
    "loss_summary = pretrain_model(\n",
    "    model                 = mdl_siamese,\n",
    "    train_dataloader      = trainloader,\n",
    "    epochs                = 50,\n",
    "    optimizer             = optimizer,\n",
    "    loss_func             = lossFnc,\n",
    "    preaugmenter          = preaugmenter,\n",
    "    augmenter             = augmenter,\n",
    "    lr_scheduler          = scheduler,\n",
    "    EarlyStopper          = earlystop,\n",
    "    validation_dataloader = valloader,\n",
    "    validation_loss_func  = lossVal,\n",
    "    validation_loss_args  = validation_loss_args,\n",
    "    verbose               = verbose,\n",
    "    device                = device,\n",
    "    return_loss_info      = True,\n",
    "    mask_tokens           = True,\n",
    "    both_mask_and_aug     = True,\n",
    "    mask_percentage       = 0.2,\n",
    "    token_num             = 498\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9185c4-5d37-43da-9dda-849889e90037",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9ec8a1-9dc4-4e34-822f-cfac133aec54",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe277e75-2a6b-4c68-88ab-1bfac9424c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop.restore_best_weights(mdl_siamese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3babb496-facf-46e6-ae19-732084b939b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = 'Results/Pretraining/Models/vicreg_32ch_128emb_50lam_75mu_10nu_100ep.pt'\n",
    "mdl_siamese.to(device='cpu')\n",
    "mdl_siamese.eval()\n",
    "torch.save(mdl_siamese.state_dict(), savepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
